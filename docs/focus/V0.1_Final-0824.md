# V0.1 Final Actionables — 2025-08-24

Task receipt and plan

- What I'm doing next: extract actionables from `V0.1_Finalized.md` and `V0.1_Current-status+pending_0824.md`, create a single verified checklist document with clear priorities, estimates, and verification instructions, then commit and push it to the feature branch.

How this document is used

- Work is performed in strict sequence top→down. Each action item must be implemented, then marked as "[x] Verified" in this document with a one-line verification note and a reference (commit hash / PR / test run) before the team begins the next item.

Checklist (actionables to reach finalized V0.1)

1. Image Generation Pipeline — Gemini integration (Priority: 1) — Estimate: 4h

   - [x] Add production Gemini image generation implementation behind env guard
     - Notes: implement `generateWithGemini(payload)` in `server/imageGenerator.js` and wire where `generateWithGemini` placeholder exists.
     - Verification: [x] Verified — commit `97ce0ed`: `generateWithGemini` implemented and gated behind `USE_REAL_AI`; focused server Vitest run (image generator + jobs tests) passed locally (4 tests).
   - [ ] Add image quality validation (DPI, dimensions, format)
   - [x] Add image quality validation (DPI, dimensions, format)
     - Verification: [x] Verified — implemented `server/imageValidation.mjs` and unit tests (`server/__tests__/imageValidation.test.mjs`). Server Vitest run shows unit & helper tests passing; image validation helper available for pipeline integration.
   - [ ] Add rasterization and format conversion tests (SVG→PNG via `sharp` when available)
         Verification: update this item with `[x] Verified` + one-line note and commit/PR hash.

- [x] Server test suite green (server): 17 passed (27 tests) — Verification: commit `84fbeb7`: server tests all passing (17 passed, 27 tests, duration 30.11s)

- [x] Orchestrator, prompts, and verification wiring implemented (partial) - Verification: `feat/image-generation-pipeline` branch contains `server/imageGenerator.js` with `generatePoemAndImage`, verification hardening, and API integration; artifacts appear in `server/samples/images/` (see docs/IMG_GEN_API.md).
  - [x] Implemented ESM adapter `server/imageGenerator.js` with offline Gemini stub, `generatePoemAndImage`, atomic `.tmp` write/rename behavior, and helper verifiers. Verification: commit `41ede8e` on branch `feat/image-gen-pipeline-impl`; smoke harness `server/test-imageGenerator.mjs` ran successfully (printed visualPrompt, imagePath, size).
  - [x] Added fetch timeout/retries, gated Gemini adapter (best-effort), rasterization helper and Vitest tests. Verification: commits `97ce0ed` and `866e9b9`; Vitest run: 3 test files, 4 tests passed (local run: `npx vitest run __tests__/ --reporter dot`).

2. Background Job Queue — SQLite-backed jobs (Priority: 2) — Estimate: 3h

   - [ ] Add `jobs` table schema to DB initialization (fields: id, payload JSON, state, progress, file_path, error, created_at, updated_at, locked_by, locked_at)
   - [ ] Implement `server/jobs.js` helpers: `enqueueJob`, `getJob`, `claimNextJob`, `updateJobProgress`, `finalizeJob`, `failJob`
   - [x] Implement `server/jobs.js` helpers: `enqueueJob`, `getJob`, `claimNextJob`, `updateJobProgress`, `finalizeJob`, `failJob`
     - Verification: [x] Verified — `server/jobs.js` implemented and covered by unit tests (`server/__tests__/jobs.test.mjs`). Jobs DB helpers exercised by worker and integration tests.
   - [ ] Update `POST /api/export/job` to call `enqueueJob(payload)` and return jobId immediately (keep in-memory fallback path)
   - [ ] Add `server/worker-sqlite.js` — polling worker that claims jobs, calls `processExportJob(job)`, writes to `server/samples/exports/` using atomic temp-write + rename, updates progress
   - [x] Add `server/worker-sqlite.js` — polling worker that claims jobs, calls `processExportJob(job)`, writes to `server/samples/exports/` using atomic temp-write + rename, updates progress
     - Verification: [x] Verified — `server/worker-sqlite.mjs` (CLI) implemented; unit and integration worker tests added (`server/__tests__/worker.test.mjs`, `server/__tests__/worker-integration.test.mjs`) and pass locally. Note: an end-to-end test (`__tests__/e2e.worker.test.mjs`) currently reports a failure (job remained `queued`) — investigation deferred to next session; worker unit/integration behavior validated.

- Verification update: [x] Verified — fixed E2E worker test (`server/__tests__/e2e.worker.test.mjs`) so spawned worker claims and finalizes jobs when `JOBS_DB` is provided; added `server/worker-sqlite.cjs` and CommonJS-compatible `server/jobs.js`. Local run: Vitest e2e test passed (1/1). Commit(s): local edits on `feat/image-gen-pipeline-impl` (test-run logs captured).
- [ ] Add recovery pass: return long-processing `processing` jobs to `queued` after X minutes
      Verification: mark `[x] Verified` + note including a smoke export run and sample job record.

---

## Recent CI / Test Results

- Server package local vitest run: `Test Files  22 passed (22)\n      Tests  33 passed (33)\n   Start at  15:09:27\n   Duration  11.52s (transform 239ms, setup 0ms, collect 3.88s, tests 13.38s, environment 5ms, prepare 2.23s)`

Verification: [x] Verified — server test suite green for this feature branch run (22 files / 33 tests passed locally). See `server/__tests__/` additions: `jobs.requeue.test.mjs` and supporting smoke script `server/scripts/run_jobs_requeue_test.js`.

## Environment variables for job queue & recovery

Add the following notes about environment configuration used by the new SQLite-backed job queue and recovery pass:

- `JOBS_DB` — Optional. Path to the SQLite jobs database file. Default: `data/jobs.db` (relative to repo root). If provided, the server opens the DB at startup and the `/api/export/job` endpoint will enqueue into this DB. Tests can set `JOBS_DB` to a temporary path to isolate test state.

- `JOBS_RECOVERY_INTERVAL_MS` — Optional. Milliseconds between periodic recovery passes that call `requeueStaleJobs`. Default: `300000` (5 minutes). Set lower in tests or CI if you want faster recovery cycles.

- `JOBS_STALE_MS` — Optional. Milliseconds threshold used by `requeueStaleJobs` to consider a `processing` job stale. Default: `600000` (10 minutes).

Usage notes:

- The server opens the jobs DB during startup (if `jobs` module present) and stores the handle on `module.exports._jobsDb`. The recovery timer is started at `JOBS_RECOVERY_INTERVAL_MS` and calls `requeueStaleJobs(module.exports._jobsDb, JOBS_STALE_MS)`.
- On graceful shutdown (`SIGINT`/`SIGTERM`) the server clears the recovery timer and closes the jobs DB handle.

Recommendation: In CI or local test runs, set `JOBS_DB` to a temp file path and reduce `JOBS_RECOVERY_INTERVAL_MS` to speed deterministic test verification.

CI notes:

- The repository includes a dedicated PR workflow: `.github/workflows/server-tests-pr.yml` (and a variant `ci-server-tests-pr.yml`). Both workflows explicitly run the server test command using `npm --prefix server test` and set Chrome-related env vars (in `ci-server-tests-pr.yml`) so Puppeteer uses system Chrome in CI:

  - `PUPPETEER_SKIP_CHROMIUM_DOWNLOAD: "true"`
  - `CHROME_PATH: /usr/bin/google-chrome-stable`

- The PR workflow also runs the E2E worker test explicitly (`npm --prefix server run test:run -- __tests__/e2e.worker.test.mjs`) to ensure the job-queue/worker E2E stays covered in CI.

This matches the local test run above and should allow green CI runs once commits are pushed to a PR.

3. PDF Quality & Export Robustness (Priority: 3) — Estimate: 3h

   - [ ] Add basic quality checks: DPI heuristic, page size, and required font markers
   - [ ] Harden PDF generation error handling (timeouts, Puppeteer launch errors, write failures)
   - [ ] Add non-fatal PDF validation step in `server/pdfGenerator.js` with warnings for CI
         Verification: `[x] Verified` with test artifact path and brief test summary.

4. E2E Testing & Error Scenarios (Priority: 4) — Estimate: 4h

   - [ ] Full E2E test for summer poems flow (prompt → preview → export) using existing smoke harness or Puppeteer-core
   - [ ] Add tests for AI service failure modes (simulate Gemini errors / timeouts)
   - [ ] Add tests for image generation failures and PDF export failures
         Verification: `[x] Verified` with test run output (CI job / local artifact) and reference.

5. UI Polish & UX (Priority: 5) — Estimate: 2h

   - [ ] Add summer-specific prompt guidance in prompt UI
   - [ ] Improve export progress UI (percent / stage messages) in `client` components
   - [ ] Improve error messages and retry affordances on the UI
         Verification: `[x] Verified` with screenshot or commit note.

6. Documentation & Developer Experience (Priority: 6) — Estimate: 2h

   - [ ] Complete API docs for `/api/export/book`, `/api/export/job`, `/api/preview` including request/response schemas and examples
   - [ ] Update `.devcontainer/README.md` and `README.md` with steps to run the worker and how to provide Gemini credentials
   - [ ] Add a short "How to verify V0.1" section describing smoke commands and artifact locations
         Verification: `[x] Verified` with link to updated docs and commit/PR.

7. CI / Smoke Automation (Priority: 7) — Estimate: 2h
   - [ ] Add/adjust CI job to run in-process export verification and upload artifacts (if not present or flaky)
   - [ ] Ensure `server/scripts/smoke-export.sh` is run and validated in CI as a gate (verify PDF magic bytes)
         Verification: `[x] Verified` with CI run link or logs.

Cross-cutting items

- [ ] Add monitoring/logging for worker (progress logs, failures) — small logrotate or retention note (0.5h)
- [ ] Ensure sample output artifacts are written to `server/test-artifacts/` or `server/samples/exports/` with unique temp names (0.5h)

Total remaining estimate: ~15–18 hours (includes small cross-cutting tasks and buffer)

Execution rules

- Each item must be checked off here before the next item begins. Checking off requires:
  1. Code committed to feature branch (or PR merged into this branch) with a clear commit message
  2. A one-line verification note in this document referencing commit/PR hash and brief outcome
  3. Where applicable, an automated test or smoke run that produced an artifact (attach artifact path)

How to check off an item

- Edit this file, change the checkbox from `[ ]` to `[x]`, add a one-line verification note under that item with commit hash or brief test artifact info, commit the change, and push.

Immediate next step

- Start with "Image Generation Pipeline — Gemini integration" (item 1). Implement `generateWithGemini` behind an env var and add a minimal test that exercises the new code path; then update this document to `[x] Verified` with the commit hash.

---

Notes

- Estimates assume a single engineer working with current repo knowledge and local devcontainer available. Parallelization can reduce wall-clock time.
- If Gemini access is not available, implement a small toggle that uses the offline SVG stub generator but still validates the code path; record that as a temporary verification step until real API keys are provided.

---

## Addenda — Reference script (poem-to-image-cloudflare.js)

Note: The script below is provided as a reference implementation and sample workflow. Do NOT copy it into the codebase verbatim. If you need its functionality, copy the relevant functions into `server/imageGenerator.js` or another appropriate module, adapt auth and env handling, and gate behavior behind env flags as described in this document.

The script is included here to serve as the actionable implementation checklist for Item 1 (Image Generation Pipeline). It demonstrates the intended poem→prompt→image flow, expected response handling, and artifact saving. Use it as the canonical reference when implementing `generateWithGemini`, `generateWithCloudflare`, and related wiring.

```javascript
// poem-to-image-cloudflare.js

import fetch from "node-fetch";
import fs from "fs";

// --- Type definitions for API responses ---
/** @typedef {Object} GeminiError {
 *   error: {
 *     code: number,
 *     message: string,
 *     status: string
 *   }
 * } */

/** @typedef {Object} GeminiContent {
 *   parts: Array<{text: string}>
 * } */

/** @typedef {Object} GeminiCandidate {
 *   content: GeminiContent,
 *   finishReason: string
 * } */

/** @typedef {Object} GeminiResponse {
 *   candidates: GeminiCandidate[]
 * } */

// --- CONFIGURATION: Replace with your actual Gemini and Cloudflare details ---
const GEMINI_API_KEY = process.env.GEMINI_API_KEY || "YOUR_GEMINI_API_KEY";
const GEMINI_API_URL = process.env.GEMINI_API_URL || "YOUR_GEMINI_API_URL";
const CLOUDFLARE_ACCOUNT_ID =
  process.env.CLOUDFLARE_ACCOUNT_ID || "YOUR_CLOUDFLARE_ACCOUNT_ID";
const CLOUDFLARE_API_TOKEN =
  process.env.CLOUDFLARE_API_TOKEN || "YOUR_CLOUDFLARE_API_TOKEN";
// --------------------------------------------------------------------------

/**
 * A generic function to call the Gemini API.
 * @param {string} prompt - The text prompt to send.
 * @returns {Promise<string>} The generated text from the model.
 */
async function generateWithGemini(prompt) {
  const url = `${GEMINI_API_URL}?key=${GEMINI_API_KEY}`;
  const headers = { "Content-Type": "application/json" };
  const body = JSON.stringify({
    contents: [{ parts: [{ text: prompt }] }],
  });

  try {
    const response = await fetch(url, { method: "POST", headers, body });
    if (!response.ok) {
      /** @type {GeminiError} */
      const errorData = await response.json();
      if (errorData && typeof errorData === "object" && "error" in errorData) {
        throw new Error(`Gemini API Error: ${JSON.stringify(errorData.error)}`);
      }
      throw new Error(`Gemini API Error: Unknown error structure`);
    }

    /** @type {GeminiResponse} */
    const data = await response.json();

    // Type-safe access with runtime validation
    if (!data || !Array.isArray(data.candidates)) {
      throw new Error(
        "Invalid API response structure: missing candidates array"
      );
    }

    const textContent = data.candidates[0]?.content?.parts?.[0]?.text;

    if (textContent) {
      return textContent;
    } else {
      // This handles cases where the response is successful but empty (e.g., due to safety filters)
      // or has an unexpected structure.
      console.error(
        "Unexpected response structure from Gemini API:",
        JSON.stringify(data, null, 2)
      );
      throw new Error("Could not extract text from Gemini API response.");
    }
    // --- ROBUSTNESS FIX ENDS HERE ---
  } catch (error) {
    console.error("Error calling Gemini API:", error.message);
    throw error; // Re-throw the error so the main function knows to stop
  }
}

/**
 * Calls the Cloudflare Workers AI API to generate an image.
 * @param {string} prompt - The visual prompt for the image.
 * @returns {Promise<Buffer>} A buffer containing the generated PNG image data.
 */
async function generateWithCloudflare(prompt) {
  // This is the model we'll use. Cloudflare offers several.
  const model = "@cf/stabilityai/stable-diffusion-xl-base-1.0";
  const url = `https://api.cloudflare.com/client/v4/accounts/${CLOUDFLARE_ACCOUNT_ID}/ai/run/${model}`;

  const headers = {
    Authorization: `Bearer ${CLOUDFLARE_API_TOKEN}`,
    "Content-Type": "application/json",
  };

  const body = JSON.stringify({ prompt });

  try {
    const response = await fetch(url, { method: "POST", headers, body });
    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Cloudflare API Error: ${response.status} ${errorText}`);
    }

    // IMPORTANT: Cloudflare returns the raw image data directly, not JSON.
    // We need to get it as an ArrayBuffer and then convert it to a Node.js Buffer.
    const imageArrayBuffer = await response.arrayBuffer();
    return Buffer.from(imageArrayBuffer);
  } catch (error) {
    console.error("Error calling Cloudflare AI API:", error);
    throw error;
  }
}

/**
 * Main function to run the full poem-to-image workflow.
 */
async function main() {
  console.log("--- Step 1: Generating a poem... ---");
  const poemTheme =
    "an ancient, moss-covered robot sleeping in a sunlit forest clearing.";
  const poemGenerationPrompt = `Write a short, evocative, six-line poem about "${poemTheme}". Use rich, visual language.`;

  const poem = await generateWithGemini(poemGenerationPrompt);
  console.log("Generated Poem:\n---\n" + poem + "\n---");

  console.log("\n--- Step 2: Creating a visual prompt from the poem... ---");
  const imagePromptGenerationPrompt = `
            Based on the following poem, create a highly detailed and descriptive prompt for an AI image generator.
            Focus on the mood, lighting, style, and specific visual elements. The prompt should be a single paragraph.

            Poem:
            ${poem}
      `;

  const visualPrompt = await generateWithGemini(imagePromptGenerationPrompt);
  console.log("Generated Visual Prompt:\n---\n" + visualPrompt + "\n---");

  console.log("\n--- Step 3: Generating the image with Cloudflare AI... ---");
  const imageBuffer = await generateWithCloudflare(visualPrompt);

  // Ensure the output directory exists
  const outputDir = "./samples/images";
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }

  // Use the same timestamp for all related files
  const timestamp = Date.now();
  const imageOutputPath = `${outputDir}/poem_image_${timestamp}.png`;
  const poemOutputPath = `${outputDir}/poem_text_${timestamp}.txt`;
  const poemPromptPath = `${outputDir}/poem_prompt-text_${timestamp}.txt`;
  const imagePromptPath = `${outputDir}/poem_prompt-image_${timestamp}.txt`;

  // Save all files: generated content and their prompts
  fs.writeFileSync(imageOutputPath, imageBuffer);
  fs.writeFileSync(poemOutputPath, poem);
  fs.writeFileSync(poemPromptPath, poemGenerationPrompt);
  fs.writeFileSync(imagePromptPath, visualPrompt);

  console.log(`\n✅ Success! Files saved:
      - Image: ${imageOutputPath}
      - Poem: ${poemOutputPath}
      - Poem Prompt: ${poemPromptPath}
      - Image Prompt: ${imagePromptPath}`);
}

// Run the main workflow
main().catch((error) => {
  console.error("\nWorkflow failed.", error.message);
});
```

## High-level plan

Implement the Image Generation Pipeline exactly as the working reference (`docs/reference/IMG_GEN_CloudflareWorker.md` and its addenda script) while keeping all production-impacting behavior gated behind opt-in environment flags. Use the reference script as the canonical workflow (poem → visual prompt → image), and migrate needed functions into `server/imageGenerator.js` and a small smoke harness. Verify each change with tests or a gated smoke run, then mark the checklist item as verified.

Principles:

- Do not copy the reference script into the codebase verbatim; extract and adapt functions into `server/` modules.
- Gate all real model calls behind `USE_REAL_AI=true` or `IMAGE_HARDEN=true` to avoid accidental credit use.
- Prefer local mocks and offline tests in CI; only run real-service smoke runs intentionally.
- Use atomic writes, content-type validation, and minimal image-quality checks before persisting artifacts.

## Actionable checklist (implement in order, small reversible steps)

1. Create feature branch

- Command: `git switch -c feat/image-gen-pipeline-impl`

2. Implement `server/imageGenerator.js` (adapter)

- Export: `generateWithGemini(prompt)`, `generateWithCloudflare(prompt)`, `generatePoemAndImage(theme, opts)`.
- Gate external calls behind `USE_REAL_AI` or `IMAGE_HARDEN` (default: offline stubs).
- Follow reference response handling and artifact naming conventions.

3. Soft env validation

- Non-blocking warnings when credentials are placeholders.

4. Add unit/integration tests (mock Gemini + Cloudflare)

- Vitest tests that mock network calls and assert artifact generation logic.

5. Add a small CLI harness `server/scripts/run-image-gen.js` (optional)

- Calls `generatePoemAndImage` and writes artifacts when `USE_REAL_AI` is set.

6. Add atomic writes & content checks

- Write images to `.tmp` then rename; validate `Content-Type` starts with `image/` and minimal size before write.

7. Add light prompt moderation/sanity checks (gated)

8. Add image-quality validation (sharp checks) and generate `image_validation_[timestamp].json`

9. Wire job queue smoke test (worker)

- Implement worker to claim jobs and call the adapter; write artifacts to `server/samples/exports/` using atomic writes.

10. Docs & verification

- After implementation and test/smoke verification, mark item 1 as `[x] Verified` with a one-line note and commit/PR hash in this document.

Notes: each step is small, reversible, and designed to minimize model calls during development. Proceed step-by-step and run tests/mocks before any real-model smoke runs.
