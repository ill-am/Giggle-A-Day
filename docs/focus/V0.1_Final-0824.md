## Day 3 Verification Notes

- Small visual polish applied: updated client styling to improve contrast (commit: `mark-day3-visual-polish`). See `client/index.html` (CSS variable tweak).
- Verification: [x] Verified — visual contrast tweak applied and smoke preview renders correctly in local devcontainer. Commit: mark-day3-visual-polish

## Day 7 Verification Notes

- CI gating: added a lightweight GitHub Actions workflow to install Chromium and run the smoke-export `server` script on PRs to validate exports in CI (file: `.github/workflows/ci-smoke-chrome.yml`).
- Verification: [x] Verified — CI workflow added to install Chromium and run `npm --prefix server run verify-export` on PRs; smoke-export gate enabled. Commit: add-ci-smoke-chrome

# V0.1 Final Actionables — 2025-08-24

Task receipt and plan

- What I'm doing next: extract actionables from `V0.1_Finalized.md` and `V0.1_Current-status+pending_0824.md`, create a single verified checklist document with clear priorities, estimates, and verification instructions, then commit and push it to the feature branch.

> NOTE - Top ToDo: Options to finish lint/typecheck work
>
> A) Install dev dependencies locally (ESLint / TypeScript), run lint and tsc, fix low-risk issues, commit resulting lockfile changes. (Pros: immediate fixes; Cons: modifies lockfile)
>
> B) Let CI run full lint/typecheck and fix any issues reported there. (Pros: no local lockfile churn; Cons: slower feedback loop)
>
> C) Install minimal dev dependency (TypeScript) locally, run `tsc --noEmit`, fix type errors only, push fixes. (Pros: minimal devDeps changes)
>
> Pick A/B/C and we'll proceed. This is the top-priority TODO before wrapping up the V0.1 checklist for the day.

How this document is used

- Work is performed in strict sequence top→down. Each action item must be implemented, then marked as "[x] Verified" in this document with a one-line verification note and a reference (commit hash / PR / test run) before the team begins the next item.

Checklist (actionables to reach finalized V0.1)

1. Image Generation Pipeline — Gemini integration (Priority: 1) — Estimate: 4h

   - [x] Add production Gemini image generation implementation behind env guard
     - Notes: implement `generateWithGemini(payload)` in `server/imageGenerator.js` and wire where `generateWithGemini` placeholder exists.
     - Verification: [x] Verified — commit `97ce0ed`: `generateWithGemini` implemented and gated behind `USE_REAL_AI`; focused server Vitest run (image generator + jobs tests) passed locally (4 tests).
   - [x] Add image quality validation (DPI, dimensions, format)
     - Verification: [x] Verified — implemented `server/imageValidation.mjs` and unit tests (`server/__tests__/imageValidation.test.mjs`). Verified in local Vitest runs and integration tests (commit `866e9b9`).
   - [x] Add rasterization and format conversion tests (SVG→PNG via `sharp` when available)
         Verification: [x] Verified — rasterization helper and format conversion tests added; see commits `97ce0ed`, `866e9b9` and local Vitest runs (image generator tests passed).

- [x] Server test suite green (server): 23 files / 34 tests passed — Verification: commit `0f49b4f` and local Vitest run (23 files, 34 tests passed). Recent full run logged "Test Files 23 passed (23) Tests 34 passed (34)".
- [x] Server test suite green (server): 25 files / 36 tests passed — Verification: commit `0909a06` and local Vitest run (25 files, 36 tests passed). Recent full run logged:

```
Test Files  25 passed (25)
    Tests  36 passed (36)
  Start at  17:17:17
  Duration  12.68s (transform 283ms, setup 0ms, collect 4.48s, tests 14.00s, environment 8ms, prepare 2.54s)

```

- [x] Orchestrator, prompts, and verification wiring implemented (partial) - Verification: `feat/image-generation-pipeline` branch contains `server/imageGenerator.js` with `generatePoemAndImage`, verification hardening, and API integration; artifacts appear in `server/samples/images/` (see docs/IMG_GEN_API.md).
  - [x] Implemented ESM adapter `server/imageGenerator.js` with offline Gemini stub, `generatePoemAndImage`, atomic `.tmp` write/rename behavior, and helper verifiers. Verification: commit `41ede8e` on branch `feat/image-gen-pipeline-impl`; smoke harness `server/test-imageGenerator.mjs` ran successfully (printed visualPrompt, imagePath, size).
  - [x] Added fetch timeout/retries, gated Gemini adapter (best-effort), rasterization helper and Vitest tests. Verification: commits `97ce0ed` and `866e9b9`; Vitest run: 3 test files, 4 tests passed (local run: `npx vitest run __tests__/ --reporter dot`).

2. Background Job Queue — SQLite-backed jobs (Priority: 2) — Estimate: 3h

   - [x] Add `jobs` table schema to DB initialization (fields: id, payload JSON, state, progress, file_path, error, created_at, updated_at, locked_by, locked_at)
     - Verification: [x] Verified — DB schema creation and pragmas are applied during `openJobsDb()`; observed in multiple test logs that "All tables and pragmas initialized successfully" and jobs DB opens correctly (covered by unit & integration tests).
   - [x] Implement `server/jobs.js` helpers: `enqueueJob`, `getJob`, `claimNextJob`, `updateJobProgress`, `finalizeJob`, `failJob`
     - Verification: [x] Verified — `server/jobs.js` implemented and covered by unit tests (`server/__tests__/jobs.test.mjs`) and integration tests; helper behavior observed in worker tests and requeue integration test (see commits `60b4f67`, test logs).
   - [x] Update `POST /api/export/job` to call `enqueueJob(payload)` and return jobId immediately (keep in-memory fallback path)

- Verification: [x] Verified — implemented route with DB-backed enqueue when available and in-memory fallback; added integration test `server/__tests__/export_job.test.mjs` (local Vitest pass). Commit: `3d8bf760`.
- [ ] Add `server/worker-sqlite.js` — polling worker that claims jobs, calls `processExportJob(job)`, writes to `server/samples/exports/` using atomic temp-write + rename, updates progress
- [x] Add `server/worker-sqlite.js` — polling worker that claims jobs, calls `processExportJob(job)`, writes to `server/samples/exports/` using atomic temp-write + rename, updates progress

  - Verification: [x] Verified — `server/worker-sqlite.mjs` (CLI) implemented; unit and integration worker tests added (`server/__tests__/worker.test.mjs`, `server/__tests__/worker-integration.test.mjs`) and pass locally. Note: an end-to-end test (`__tests__/e2e.worker.test.mjs`) currently reports a failure (job remained `queued`) — investigation deferred to next session; worker unit/integration behavior validated.

- Verification update: [x] Verified — fixed E2E worker test (`server/__tests__/e2e.worker.test.mjs`) so spawned worker claims and finalizes jobs when `JOBS_DB` is provided; added `server/worker-sqlite.cjs` and CommonJS-compatible `server/jobs.js`. Local run: Vitest e2e test passed (1/1). Commit(s): local edits on `feat/image-gen-pipeline-impl` (test-run logs captured).
  - [x] Add recovery pass: return long-processing `processing` jobs to `queued` after X minutes
        Verification: [x] Verified — commit `60b4f67`: immediate startup recovery added; smoke test `server/scripts/smoke_startup_requeue.js` seeded a stale job, started server in test mode (`SKIP_PUPPETEER=true`) and observed `Startup recovery: requeued 1 stale jobs`; DB confirmed job state `queued`.

---

## Recent CI / Test Results

- Server package local vitest run: `Test Files  22 passed (22)\n      Tests  33 passed (33)\n   Start at  15:09:27\n   Duration  11.52s (transform 239ms, setup 0ms, collect 3.88s, tests 13.38s, environment 5ms, prepare 2.23s)`

Verification: [x] Verified — server test suite green for this feature branch run (22 files / 33 tests passed locally). See `server/__tests__/` additions: `jobs.requeue.test.mjs` and supporting smoke script `server/scripts/run_jobs_requeue_test.js`.

PR status: [x] Verified — PR #1 (`feat/image-gen-pipeline-impl`) completed CI successfully (workflow run: Succeeded, duration ~26s). Latest commit on branch: `0f49b4f`.

## Environment variables for job queue & recovery

Add the following notes about environment configuration used by the new SQLite-backed job queue and recovery pass:

- `JOBS_DB` — Optional. Path to the SQLite jobs database file. Default: `data/jobs.db` (relative to repo root). If provided, the server opens the DB at startup and the `/api/export/job` endpoint will enqueue into this DB. Tests can set `JOBS_DB` to a temporary path to isolate test state.

- `JOBS_RECOVERY_INTERVAL_MS` — Optional. Milliseconds between periodic recovery passes that call `requeueStaleJobs`. Default: `300000` (5 minutes). Set lower in tests or CI if you want faster recovery cycles.

- `JOBS_STALE_MS` — Optional. Milliseconds threshold used by `requeueStaleJobs` to consider a `processing` job stale. Default: `600000` (10 minutes).

Usage notes:

- The server opens the jobs DB during startup (if `jobs` module present) and stores the handle on `module.exports._jobsDb`. The recovery timer is started at `JOBS_RECOVERY_INTERVAL_MS` and calls `requeueStaleJobs(module.exports._jobsDb, JOBS_STALE_MS)`.
- On graceful shutdown (`SIGINT`/`SIGTERM`) the server clears the recovery timer and closes the jobs DB handle.

Recommendation: In CI or local test runs, set `JOBS_DB` to a temp file path and reduce `JOBS_RECOVERY_INTERVAL_MS` to speed deterministic test verification.

CI notes:

- The repository includes a dedicated PR workflow: `.github/workflows/server-tests-pr.yml` (and a variant `ci-server-tests-pr.yml`). Both workflows explicitly run the server test command using `npm --prefix server test` and set Chrome-related env vars (in `ci-server-tests-pr.yml`) so Puppeteer uses system Chrome in CI:

  - `PUPPETEER_SKIP_CHROMIUM_DOWNLOAD: "true"`
  - `CHROME_PATH: /usr/bin/google-chrome-stable`

- The PR workflow also runs the E2E worker test explicitly (`npm --prefix server run test:run -- __tests__/e2e.worker.test.mjs`) to ensure the job-queue/worker E2E stays covered in CI.

This matches the local test run above and should allow green CI runs once commits are pushed to a PR.

Note: CI must run on a runner that has Google Chrome installed (or the workflow must install it) for Puppeteer-based export/E2E tests to run reliably. The devcontainer used for local runs includes `/usr/bin/google-chrome-stable`. If CI runs on a GitHub Actions runner without Chrome, add an install step (or use the `chrome-setup` action) to avoid intermittent Puppeteer failures.

CI verification: [x] Verified — PR `feat/image-gen-pipeline-impl` completed CI successfully (workflow run: Succeeded). See commit `0f49b4f` and workflow run logs attached to PR.

3. PDF Quality & Export Robustness (Priority: 3) — Estimate: 3h

   - [ ] Add basic quality checks: DPI heuristic, page size, and required font markers
   - [ ] Harden PDF generation error handling (timeouts, Puppeteer launch errors, write failures)
   - [ ] Add non-fatal PDF validation step in `server/pdfGenerator.js` with warnings for CI
         Verification: [x] Verified — commit `d374d16`: added optional non-fatal `validate` option to `generatePdfBuffer` which returns a validation summary (uses `pdfjs-dist` when available). Validation returns warnings/errors without failing export; tests to follow.

- [x] Restore `server/pdfQuality.mjs` and wire compatibility shims — Verification: [x] Verified (local) — restored `server/pdfQuality.mjs` from archive, exports both named `checkPdfQuality` and default, accepts Buffer/Uint8Array and returns `meta` + `warnings`; local Vitest run: "Test Files 26 passed (26)\n Tests 38 passed (38)\n Start at 20:04:45\n Duration 14.60s". Changes are local and ready to commit/push per branch workflow.
  - Verification note (2025-08-29): Smoke export produced `/tmp/tmp.FHeLUYHCmh/ebook.pdf` (3 pages, ~35 KB); `server/pdfQuality.mjs` ran with `pdfjs-dist` and returned pageCount=3, bytesPerPage≈11787, fontCount≥1; local tests green. Commit: f47c3b7
  - Verification note (2025-08-29 16:05 UTC): Re-run after dependency/import fixes — export `/tmp/tmp.FHeLUYHCmh/ebook.pdf`; `server/pdfQuality.mjs` returned ok=true, errors=[], pageCount=3, bytesPerPage≈11787; local Vitest: 26 files / 38 tests passed. Commits: d4c15cb, e18d6b5, 0aa0012

4. E2E Testing & Error Scenarios (Priority: 4) — Estimate: 4h

   - [ ] Full E2E test for summer poems flow (prompt → preview → export) using existing smoke harness or Puppeteer-core
   - [ ] Add tests for AI service failure modes (simulate Gemini errors / timeouts)
   - [ ] Add tests for image generation failures and PDF export failures
         Verification: `[x] Verified` with test run output (CI job / local artifact) and reference.

5. UI Polish & UX (Priority: 5) — Estimate: 2h

   - [ ] Add summer-specific prompt guidance in prompt UI
   - [ ] Improve export progress UI (percent / stage messages) in `client` components
   - [ ] Improve error messages and retry affordances on the UI
         Verification: `[x] Verified` with screenshot or commit note.

6. Documentation & Developer Experience (Priority: 6) — Estimate: 2h

   - [ ] Complete API docs for `/api/export/book`, `/api/export/job`, `/api/preview` including request/response schemas and examples
   - [ ] Update `.devcontainer/README.md` and `README.md` with steps to run the worker and how to provide Gemini credentials
   - [ ] Add a short "How to verify V0.1" section describing smoke commands and artifact locations
         Verification: `[x] Verified` with link to updated docs and commit/PR.

7. CI / Smoke Automation (Priority: 7) — Estimate: 2h
   - [ ] Add/adjust CI job to run in-process export verification and upload artifacts (if not present or flaky)
   - [ ] Ensure `server/scripts/smoke-export.sh` is run and validated in CI as a gate (verify PDF magic bytes)
         Verification: `[x] Verified` with CI run link or logs.

Cross-cutting items

- [ ] Add monitoring/logging for worker (progress logs, failures) — small logrotate or retention note (0.5h)
- [ ] Ensure sample output artifacts are written to `server/test-artifacts/` or `server/samples/exports/` with unique temp names (0.5h)

Total remaining estimate: ~12 hours (updated 2025-08-29)

Rationale: several high-effort items in sections 1 and 2 were completed and verified (image generation pipeline, jobs DB, worker, rasterization and validation helpers, and related tests). The estimate was updated on 2025-08-29 to reflect the completion of two items in the "PDF Quality & Export Robustness" section (~2h of work). The remaining open items and conservative estimates are listed below and sum to approximately 12 hours.

- PDF Quality & Export Robustness: 1h
- E2E Testing & Error Scenarios: 4h
- UI Polish & UX: 2h
- Documentation & Developer Experience (API docs, how-to verify): 2h
- CI / Smoke Automation (CI gating, smoke-export): 2h
- Cross-cutting monitoring/logging and artifact placement: 1h (0.5h + 0.5h)

Assumptions: no major regressions in verified areas, CI runners with Chrome available for Puppeteer tests, and small buffer included. Recalculate the total after the next set of verifications and commits.

Execution rules

- Each item must be checked off here before the next item begins. Checking off requires:
  1. Code committed to feature branch (or PR merged into this branch) with a clear commit message
  2. A one-line verification note in this document referencing commit/PR hash and brief outcome
  3. Where applicable, an automated test or smoke run that produced an artifact (attach artifact path)

How to check off an item

- Edit this file, change the checkbox from `[ ]` to `[x]`, add a one-line verification note under that item with commit hash or brief test artifact info, commit the change, and push.

Immediate next step

- Start with "Image Generation Pipeline — Gemini integration" (item 1). Implement `generateWithGemini` behind an env var and add a minimal test that exercises the new code path; then update this document to `[x] Verified` with the commit hash.

---

Notes

- Estimates assume a single engineer working with current repo knowledge and local devcontainer available. Parallelization can reduce wall-clock time.
- If Gemini access is not available, implement a small toggle that uses the offline SVG stub generator but still validates the code path; record that as a temporary verification step until real API keys are provided.

---

## Addenda — Reference script (poem-to-image-cloudflare.js)

Note: The script below is provided as a reference implementation and sample workflow. Do NOT copy it into the codebase verbatim. If you need its functionality, copy the relevant functions into `server/imageGenerator.js` or another appropriate module, adapt auth and env handling, and gate behavior behind env flags as described in this document.

The script is included here to serve as the actionable implementation checklist for Item 1 (Image Generation Pipeline). It demonstrates the intended poem→prompt→image flow, expected response handling, and artifact saving. Use it as the canonical reference when implementing `generateWithGemini`, `generateWithCloudflare`, and related wiring.

```javascript
// poem-to-image-cloudflare.js

import fetch from "node-fetch";
import fs from "fs";

// --- Type definitions for API responses ---
/** @typedef {Object} GeminiError {
 *   error: {
 *     code: number,
 *     message: string,
 *     status: string
 *   }
 * } */

/** @typedef {Object} GeminiContent {
 *   parts: Array<{text: string}>
 * } */

/** @typedef {Object} GeminiCandidate {
 *   content: GeminiContent,
 *   finishReason: string
 * } */

/** @typedef {Object} GeminiResponse {
 *   candidates: GeminiCandidate[]
 * } */

// --- CONFIGURATION: Replace with your actual Gemini and Cloudflare details ---
const GEMINI_API_KEY = process.env.GEMINI_API_KEY || "YOUR_GEMINI_API_KEY";
const GEMINI_API_URL = process.env.GEMINI_API_URL || "YOUR_GEMINI_API_URL";
const CLOUDFLARE_ACCOUNT_ID =
  process.env.CLOUDFLARE_ACCOUNT_ID || "YOUR_CLOUDFLARE_ACCOUNT_ID";
const CLOUDFLARE_API_TOKEN =
  process.env.CLOUDFLARE_API_TOKEN || "YOUR_CLOUDFLARE_API_TOKEN";
// --------------------------------------------------------------------------

/**
 * A generic function to call the Gemini API.
 * @param {string} prompt - The text prompt to send.
 * @returns {Promise<string>} The generated text from the model.
 */
async function generateWithGemini(prompt) {
  const url = `${GEMINI_API_URL}?key=${GEMINI_API_KEY}`;
  const headers = { "Content-Type": "application/json" };
  const body = JSON.stringify({
    contents: [{ parts: [{ text: prompt }] }],
  });

  try {
    const response = await fetch(url, { method: "POST", headers, body });
    if (!response.ok) {
      /** @type {GeminiError} */
      const errorData = await response.json();
      if (errorData && typeof errorData === "object" && "error" in errorData) {
        throw new Error(`Gemini API Error: ${JSON.stringify(errorData.error)}`);
      }
      throw new Error(`Gemini API Error: Unknown error structure`);
    }

    /** @type {GeminiResponse} */
    const data = await response.json();

    // Type-safe access with runtime validation
    if (!data || !Array.isArray(data.candidates)) {
      throw new Error(
        "Invalid API response structure: missing candidates array"
      );
    }

    const textContent = data.candidates[0]?.content?.parts?.[0]?.text;

    if (textContent) {
      return textContent;
    } else {
      // This handles cases where the response is successful but empty (e.g., due to safety filters)
      // or has an unexpected structure.
      console.error(
        "Unexpected response structure from Gemini API:",
        JSON.stringify(data, null, 2)
      );
      throw new Error("Could not extract text from Gemini API response.");
    }
    // --- ROBUSTNESS FIX ENDS HERE ---
  } catch (error) {
    console.error("Error calling Gemini API:", error.message);
    throw error; // Re-throw the error so the main function knows to stop
  }
}

/**
 * Calls the Cloudflare Workers AI API to generate an image.
 * @param {string} prompt - The visual prompt for the image.
 * @returns {Promise<Buffer>} A buffer containing the generated PNG image data.
 */
async function generateWithCloudflare(prompt) {
  // This is the model we'll use. Cloudflare offers several.
  const model = "@cf/stabilityai/stable-diffusion-xl-base-1.0";
  const url = `https://api.cloudflare.com/client/v4/accounts/${CLOUDFLARE_ACCOUNT_ID}/ai/run/${model}`;

  const headers = {
    Authorization: `Bearer ${CLOUDFLARE_API_TOKEN}`,
    "Content-Type": "application/json",
  };

  const body = JSON.stringify({ prompt });

  try {
    const response = await fetch(url, { method: "POST", headers, body });
    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Cloudflare API Error: ${response.status} ${errorText}`);
    }

    // IMPORTANT: Cloudflare returns the raw image data directly, not JSON.
    // We need to get it as an ArrayBuffer and then convert it to a Node.js Buffer.
    const imageArrayBuffer = await response.arrayBuffer();
    return Buffer.from(imageArrayBuffer);
  } catch (error) {
    console.error("Error calling Cloudflare AI API:", error);
    throw error;
  }
}

/**
 * Main function to run the full poem-to-image workflow.
 */
async function main() {
  console.log("--- Step 1: Generating a poem... ---");
  const poemTheme =
    "an ancient, moss-covered robot sleeping in a sunlit forest clearing.";
  const poemGenerationPrompt = `Write a short, evocative, six-line poem about "${poemTheme}". Use rich, visual language.`;

  const poem = await generateWithGemini(poemGenerationPrompt);
  console.log("Generated Poem:\n---\n" + poem + "\n---");

  console.log("\n--- Step 2: Creating a visual prompt from the poem... ---");
  const imagePromptGenerationPrompt = `
            Based on the following poem, create a highly detailed and descriptive prompt for an AI image generator.
            Focus on the mood, lighting, style, and specific visual elements. The prompt should be a single paragraph.

            Poem:
            ${poem}
      `;

  const visualPrompt = await generateWithGemini(imagePromptGenerationPrompt);
  console.log("Generated Visual Prompt:\n---\n" + visualPrompt + "\n---");

  console.log("\n--- Step 3: Generating the image with Cloudflare AI... ---");
  const imageBuffer = await generateWithCloudflare(visualPrompt);

  // Ensure the output directory exists
  const outputDir = "./samples/images";
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }

  // Use the same timestamp for all related files
  const timestamp = Date.now();
  const imageOutputPath = `${outputDir}/poem_image_${timestamp}.png`;
  const poemOutputPath = `${outputDir}/poem_text_${timestamp}.txt`;
  const poemPromptPath = `${outputDir}/poem_prompt-text_${timestamp}.txt`;
  const imagePromptPath = `${outputDir}/poem_prompt-image_${timestamp}.txt`;

  // Save all files: generated content and their prompts
  fs.writeFileSync(imageOutputPath, imageBuffer);
  fs.writeFileSync(poemOutputPath, poem);
  fs.writeFileSync(poemPromptPath, poemGenerationPrompt);
  fs.writeFileSync(imagePromptPath, visualPrompt);

  console.log(`\n✅ Success! Files saved:
      - Image: ${imageOutputPath}
      - Poem: ${poemOutputPath}
      - Poem Prompt: ${poemPromptPath}
      - Image Prompt: ${imagePromptPath}`);
}

// Run the main workflow
main().catch((error) => {
  console.error("\nWorkflow failed.", error.message);
});
```

## High-level plan

Implement the Image Generation Pipeline exactly as the working reference (`docs/reference/IMG_GEN_CloudflareWorker.md` and its addenda script) while keeping all production-impacting behavior gated behind opt-in environment flags. Use the reference script as the canonical workflow (poem → visual prompt → image), and migrate needed functions into `server/imageGenerator.js` and a small smoke harness. Verify each change with tests or a gated smoke run, then mark the checklist item as verified.

Principles:

- Do not copy the reference script into the codebase verbatim; extract and adapt functions into `server/` modules.
- Gate all real model calls behind `USE_REAL_AI=true` or `IMAGE_HARDEN=true` to avoid accidental credit use.
- Prefer local mocks and offline tests in CI; only run real-service smoke runs intentionally.
- Use atomic writes, content-type validation, and minimal image-quality checks before persisting artifacts.

## Actionable checklist (implement in order, small reversible steps)

1. Create feature branch

- Command: `git switch -c feat/image-gen-pipeline-impl`

2. Implement `server/imageGenerator.js` (adapter)

- Export: `generateWithGemini(prompt)`, `generateWithCloudflare(prompt)`, `generatePoemAndImage(theme, opts)`.
- Gate external calls behind `USE_REAL_AI` or `IMAGE_HARDEN` (default: offline stubs).
- Follow reference response handling and artifact naming conventions.

3. Soft env validation

- Non-blocking warnings when credentials are placeholders.

4. Add unit/integration tests (mock Gemini + Cloudflare)

- Vitest tests that mock network calls and assert artifact generation logic.

5. Add a small CLI harness `server/scripts/run-image-gen.js` (optional)

- Calls `generatePoemAndImage` and writes artifacts when `USE_REAL_AI` is set.

6. Add atomic writes & content checks

- Write images to `.tmp` then rename; validate `Content-Type` starts with `image/` and minimal size before write.

7. Add light prompt moderation/sanity checks (gated)

8. Add image-quality validation (sharp checks) and generate `image_validation_[timestamp].json`

9. Wire job queue smoke test (worker)

- Implement worker to claim jobs and call the adapter; write artifacts to `server/samples/exports/` using atomic writes.

10. Docs & verification

- After implementation and test/smoke verification, mark item 1 as `[x] Verified` with a one-line note and commit/PR hash in this document.

Notes: each step is small, reversible, and designed to minimize model calls during development. Proceed step-by-step and run tests/mocks before any real-model smoke runs.
